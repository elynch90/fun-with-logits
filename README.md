# fun-with-logits
A fun time working with logits, because who doesn't love logits?


Objective
The goal of this exercise is to understand the softmax function, implement it in Python, and apply it to a set of raw scores (also called logits). Softmax is commonly used in multi-class classification problems to convert raw scores into probabilities.

Softmax Function
Softmax takes a vector of real numbers and normalizes it into a probability distribution, where the sum of all probabilities is 1. Mathematically, for an input vector 
ğ‘§
z, the softmax of element 
ğ‘§
ğ‘–
z 
i
â€‹
  is defined as:

softmax
(
ğ‘§
ğ‘–
)
=
ğ‘’
ğ‘§
ğ‘–
âˆ‘
ğ‘—
=
1
ğ‘›
ğ‘’
ğ‘§
ğ‘—
softmax(z 
i
â€‹
 )= 
âˆ‘ 
j=1
n
â€‹
 e 
z 
j
â€‹
 
 
e 
z 
i
â€‹
 
 
â€‹
 
where:

ğ‘§
ğ‘–
z 
i
â€‹
  is the i-th raw score in the input vector.
ğ‘’
ğ‘§
ğ‘–
e 
z 
i
â€‹
 
  is the exponential function applied to 
ğ‘§
ğ‘–
z 
i
â€‹
 .
âˆ‘
ğ‘—
=
1
ğ‘›
ğ‘’
ğ‘§
ğ‘—
âˆ‘ 
j=1
n
â€‹
 e 
z 
j
â€‹
 
  is the sum of exponentials of all the elements in the input vector.
